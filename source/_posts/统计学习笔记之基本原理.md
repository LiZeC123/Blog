---
title: 统计学习笔记之基本原理
date: 2024-06-06 13:23:42
categories: 统计学
tags:
    - 概率论
    - 统计学
cover_picture: images/Probability.jpg
math: true
---


概率论本质上是定义了一组接口, 满足其接口定义的任何东西都可以视为概率, 统计学则是构建在这组接口上的实际应用. 在大学的课程中, 比较侧重于学习概率论的理论知识, 而弱化统计相关的概念与方法. 本文根据<<统计学>>介绍与统计相关的基本概念与方法.

第一章 统计学基本概念
======================

总体与样本
-----------

**总体**是所研究的全部个体的集合, **样本**是从总体中抽取的一部分个体的集合. 通常情况下, 无法直接对总体进行研究, 而只能从中抽取部分个体构成一个样本.

参数与统计量
--------------

**参数**是用来描述**总体**特征的概括性数字度量. 由于总体通常是不可知的, 因此参数是一个未知的常量. 实际中, 需要根据样本计算出某些值, 然后估计参数.


**统计量**是用来描述**样本**特征的概括性数字度量. 由于抽样是随机的, 因此统计量是样本的函数.


第二章 数据的概括性度量
=======================

总数, 平均数, 中位数的概率已经非常熟悉, 不在赘述.


离散程度的度量
-----------------

### 异众比例

非众数的频率占总频率的比例. 该指标用于衡量总数对总体数据的代表程度

### 四分位差

上四分位数与下四分位数的差, 反应了中间50%的数据的离散程度.

### 离散系数

离散系数也称为变异系数, 是一组数据的标准差与平均数之比.


偏态与峰态的度量
-----------------

### 偏态系数

偏态是对数据分布对称性的度量, 对于未分组的原始数据, 可采取如下的公式计算

$$
SK = \frac{n\sum(x_i - \bar{x})^3}{(n-1)(n-2)s^3}
$$

其中$s^3$是样本的标准差的3次方. 如果一组数据是对称的, 则偏态系数为0. 如果大于1或者小于-1, 则认为是高度偏态.


### 峰态系数

峰态是相对正态分布而言的. 如果一组数据服从正态分布, 则其峰态系数为0. 若峰态系数明显不为0, 则对应的分布与正态分布相比更平或更尖.



第三章 统计量及其抽样分布
=======================


常用统计量
-------------

设$X_1, X_2, \cdots, X_n$是从总体$X$中抽取的容量为n的**一个**样本, 如果次样本构造一个函数$T=(X_1, X_2, \cdots, X_n)$不依赖任何未知参数,则称函数T是一个统计量

> 也就是字面意义上的, 可以从样本中通过统计得出的量. E(X)和D(X)等依赖实际分布的量就不是统计量

进行一次抽样(获取了n个具体的样本)就可以计算一次统计量. 在后续会讨论统计量的分布, 此时就是在说, 假设进行了k次抽样, 每次抽取n个数据时, 对应的统计量是如何分布的.

### 样本均值

$$
\bar{X} = \frac{\sum_{i=1}^n (X_i)}{n}
$$

### 样本方差

$$
S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2
$$


抽样分布
---------

### 正态分布

- [正态分布的推导过程](https://www.bilibili.com/video/BV1s441157cs/)

### 卡方分布

设随机变量$X_1, X_2, \cdots, X_n$互相独立, 且$X_i(i=1,2, \cdots, n)$服从标准正态分布, 则他们的平方和服从自由度为n的$\chi^2$分布.

对于任意一个分布, 从中抽取n个样本, 将每个具体的样本视为一个随机变量, 则这些随机变量之间应该是相互独立且服从相同分布的. 

> 从$\chi^2$分布是关于平方和的分布可以预见此分布在方差类的场景有较多的应用.

对于$\chi^2$分布有 $E(\chi^2) = n$, $D(\chi^2) = 2n$. 

从$\chi^2$分布的定义可以显然的得出$\chi^2$分布具有可加性, 即$\chi_1^2 + \chi_2^2 \sim \chi^2(n_1 + n2)$

> 从实践的角度来说, 并不需要关心卡方分布的数学表达, 仅需要能够识别出什么时候采用卡方分布即可. 但从学习的角度来说, 后续还是需要补充其数学理论.

### t分布

设随机变量$X \sim N(0,1), Y \sim \chi^2(n)$, 且X与Y相互独立, 则定义

$$
t = \frac{X}{\sqrt{Y/n}}
$$

该分布称为$t$分布, 记为$t(n)$, 其中n为自由度.

当$n >= 2$时, 有$E(t) = 0$

当$n >= 3$时, 有$D(t)=\frac{n}{n-2}$

> $t$分布与小样本理论有密切关系

### F分布

设随机变量$Y$与$Z$相互独立, 且$Y$与$Z$分别服从自由度为$m$和$n$的$\chi^2$分布, 随机变量$X$具有如下的表达式

$$
X = \frac{Y/m}{Z/n}=\frac{nY}{mZ}
$$

则称$X$服从第一自由度为$m$, 第二自由度为$n$的$F$分布, 记为$F(m, n)$.

$F$分布与$t$分布存在如下关系: 如果随机变量$X$服从$t(n)$分布, 则$X^2$服从$F(1,n)$分布, 则在回归分析的回归系数显著性检验中有用.


样本均值的分布
--------------------

设$X_1, X_2, \cdots, X_n$是从总体中抽取的随机样本, 假设总体分布为正态分布$N(\mu, \sigma^2)$, 则样本的均值依然服从正态分布, 且

$$
\bar{X} \sim N(\mu, \frac{\sigma^2}{n})
$$

以上结果表明, $\bar{X}$的期望与总体均值相同, 而方差随着**样本数量**的增加而缩小. 当n越来越大时, $\bar{X}$的散布程度越来越小, 使用$\bar{X}$估计$\mu$也就越来越准确.

> 注意区分样本大小与抽样次数. 样本越大就越能体验总体的分布情况, 因此得到的样本均值的方差就会越小. 但单纯的进行多次抽样只会得到同一个分布下的不同数据, 并不会导致分布发生变化.


中心极限定理
--------------------

设从均值为$\mu$, 方差为$\sigma^2$(有限)的**任意**一个总体中抽取样本量为n的样本, 当n充分大时, 有

$$
\bar{X} \sim N(\mu, \frac{\sigma^2}{n})
$$

中心极限定理是抽样分析理论的基础, 如果不存在中心极限定理, 即样本的抽样分布总是取决于实际的分布情况, 那么就无法在理论上进行统一的建模分析, 导致统计学的实际应用将会非常的复杂. 也正因为如此, 这个定理才称为中心极限定理.

> 以前学习的定义中, 中心极限定理表述为N个独立同分布的随机变量之和服从正态分布.  从表述上看, 似乎与以前学习的中心极限定理不同, 但实际上抽取的n个具体样本就是n个独立同分布的随机变量. 因此以上表述相当于中心极限定理在统计学上的应用.

通常将n大于等于30视为充分大. 注意n为样本大小, 即一次抽样过程中实际抽取的样本数量. n越大则对应的分布越窄, 那么进行一次抽样时, 统计量接近实际量的概率就越大.

------------------------

可通过计算机编程验证中心极限定理

```py
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# 使用泊松分布产生样本, 每次产生1000个随机数, 计算这些随机数的均值
# 进行100次采样操作, 根据中心极限定理, 均值应该服从正态分布, 
Z = [np.average(np.random.poisson(5, 1000)) for i in range(100)]


# 绘制这些数据的频率直方图
s = pd.DataFrame(Z, columns=['values'])
fig = plt.figure(figsize=(10, 6))
ax2 = fig.add_subplot(2, 1, 2)
s.hist(bins=20,alpha=0.5,ax=ax2)
s.plot(kind='kde', secondary_y=True,ax=ax2)     # 使用双坐标轴
plt.grid()

# 计算数据是否符合正态分布
shapiro(Z)
```

数据绘制的频率直方图如下所示:

![验证中心极限定理](/images/math/验证中心极限定理.PNG)

从曲线形状看, 虽然不是特别光滑, 但基本符合正态分布曲线的形状. 使用shapiro检验数据是否为正态分布的计算结果如下:

```
ShapiroResult(statistic=0.9927898049354553, pvalue=0.8750585913658142)
```

由于$p>0.05$, 因此无法拒绝原假设, 可以认为数据符合正态分布.


- [Python检验样本是否服从正态分布](https://blog.csdn.net/tszupup/article/details/108432814)
- [python生成泊松分布随机数](https://blog.51cto.com/u_16175511/7663065)

第四章 参数估计
===============

如果可以获取总体数据, 那么仅需要使用统计方法即可获得相应的特征, 例如总体均值, 方差等. 但实际情况中往往无法获取总体数据, 因此仅能够通过抽样的方式获取部分数据, 并根据这部分数据估计总体的参数.

用来估计总体参数的**统计量**称为**估计量**, 使用$\hat{\theta}$表示, 根据具体样本计算出来的统计量的数值称为估计值.



点估计与区间估计
----------------

点估计就是用样本统计量$\hat{\theta}$的某个取值直接作为总体参数$\theta$的估计值. 点估计仅有一个取值, 无法给出估计的可靠程度的度量, 因此通常给出区间估计.

区间估计在点估计的基础上, 给出总体参数的估计的一个区间范围. 由中心极限定理可知, 在重复抽样的情况下样本均值服从特定的正态分布, 可根据正态分布表得知在不同标准差范围内的概率, 例如分布在3个标准差范围内的概率为0.9973. 

由于$\bar{x}$与$\mu$的距离实际是对称的, 因此反过来也可以根据$\bar{x}$判断$\mu$在区间内的概率. 由此可以根据$\bar{x}$给出一个区间, 并得到区间的置信水平.

注意: 每抽取一次样本, 就可以计算一个唯一确定的区间. 真实的$\mu$值要么在该区间, 要么不在该区间, 并不涉及概率问题. 置信水平为95%是指重复进行抽样和计算区间的操作时, 可能有95%的操作计算出的区间包含真实的$\mu$值


一个总体参数的区间估计
-----------------------

### 总体均值的区间估计

**(正态分布且方差已知)或(非正态分布但大样本)**: 此时样本均值经过标准化后服从标准正态分布, 即

$$
z=\frac{\bar{x} - \mu}{\sigma / \sqrt{n}} \sim N(0, 1)
$$

根据标准正态分布表, 可计算不同置信水平的概率. 当给定的置信水平为$1-\alpha$时, 等价于求解如下的概率

$$
P(-z_{\alpha/2} \le z\le z_{\alpha/2}) = 1 - \alpha
$$

由于正态分布时对称的, 因此也等价于求解

$$
P(z \le z_{\alpha/2}) = 1 - \frac{\alpha}{2}
$$

> 正态分布是对称的, 中间的部分占比为$1-\alpha$, 则两端占的面积一共为$\alpha$, 因此单边就是$\frac{\alpha}{2}$

可通过[在线标准正态分布表](https://www.shuxuele.com/data/standard-normal-distribution-table.html)查询不同比例下z的取值, 例如当$\alpha=0.05$时, 查询到$z=1.96$时, `UP to Z`的面积为97.5%(即$1 - \frac{\alpha}{2}$)

将查询到的值乘以$\sigma / \sqrt{n}$即为一半区间的大小.

> 当总体方差未知时, 如果为大样本, 则可以使用样本方差代替总体方差进行计算

---------------------

**正态总体且方差未知且小样本**: 此时使用样本方差代替总体方差进行标准化后, 服从自由度为$n-1$的$t$分布, 即

$$
z=\frac{\bar{x} - \mu}{s / \sqrt{n}} \sim t(n - 1)
$$

该情况下的置信区间的计算方式与正态分布类似, 也需要查表获得$t_{\alpha/2}$的值

### 总体比例的区间估计

略, 见<<统计学>> 7.2.2 节

### 总体方差的区间估计

**正态分布**: 样本方差服从自由度为$n-1$的$\chi^2$分布. 与正态分布类似的方差查询$\chi^2$分布表获得对应的区间大小.

### 参数与分布对应关系

![一个总体参数的区间估计](/images/math/一个总体参数的区间估计.PNG)
  

两个总体参数的估计
-------------------

### 两个总体均值之差的估计

**(正态分布且方差已知)或(非正态分布但大样本)**: 两个样本的均值差标准化后服从标准正态分布, 即

$$
z = \frac{(\bar{x_1} - \bar{x_2}) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}} \sim N(0, 1)
$$

> 如果方差未知, 在大样本情况下可用样本方差替换总体方差

---------------------

**正态总体且方差未知且小样本**: 如果两个样本方差相同, 此时使用样本方差代替总体方差进行标准化后, 服从自由度为$n_1+n_2-2$的$t$分布, 即

$$
z = \frac{(\bar{x_1} - \bar{x_2}) - (\mu_1 - \mu_2)}{s_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t(n_1+n_2-2)
$$

如果两个样本的方差不相等, 则需要按照如下的方式计算自由度, 令

$$
v_1 = \frac{s_1^2}{n_1}
$$

$$
v_2 = \frac{s_2^2}{n_2}
$$

则对应的自由度为

$$
v = \frac{(v_1 +v_2)^2}{\frac{v_1^2}{n_1 - 1} + \frac{v_2^2}{n_2 - 1}}
$$

---------------------

**匹配样本**: 匹配样本是指控制其他变量的情况下得到的样本, 例如给定12名工人, 使他们分别使用方法一和方法二进行操作, 比较方法一和方法二的效果. 通过这种方法可以排除其他因素对效果的影响. 

此时在大样本下时, 每一对数据的差值标准化后服从正态分布, 小样本下时, 每一对数据的差值服从自由度为$n-1$的$t$分布, 例如大样本时置信区间为

$$
\bar{d} \pm z_{\alpha/2} \frac{\sigma_d}{\sqrt{n}}
$$

其中$\bar{d}$表示对应差值的均值, $\sigma_d$表示对应差值的标准差.



### 两个总体方差比的区间估计

实际工作中可能遇到比较两个总体方差的情况, 例如比较两种生产方法的产品性能的稳定性. 

两个样本方差比的抽样分布服从$F(n_1 -1, n_2 - 1)$分布, 可类似正态分布的方式查表计算区间长度.

### 参数与分布对应关系

![两个总体参数的区间估](/images/math/两个总体参数的区间估计.PNG)


第五章 假设检验
===============


原假设与备择假设
-----------------

原假设是我们关系的问题, 例如我们想知道一个产品的平均质量是否为某一特定值, 则可以假设

$$
H_0 : \mu = \mu_0
$$

与之相对应的假设称为备择假设, 例如

$$
H_1: \mu \ne \mu_0 
$$

原假设与备择假设互斥, 肯定原假设意味着放弃备择假设; 否定原假设意味着接受备择假设.


两类错误
-------------

项目        | 没有拒绝$H_0$         | 拒绝$H_0$
------------|----------------------|-------------------
$H_0$为真   | $1-\alpha$(正确决策)  | $\alpha$(弃真错误)
$H_0$为伪   | $\beta$(取伪错误)     | $1-\beta$(正确决策)


第一类错误是$H_0$为真, 但是拒绝$H_0$. 犯此类错误的概率通常用$\alpha$表示, 也称为$\alpha$错误.

第二类错误是$H_0$为伪, 但接受$H_0$. 犯此类错误的概率通常用$\beta$表示, 也称为$\beta$错误.

$\alpha$错误与$\beta$错误呈现此消彼长的关系, 我们通常将关心的具体的问题作为原假设, 因此通常以控制$\alpha$错误出现的概率作为目标.

> 通过增大样本量可以做到同时减小$\alpha$错误与$\beta$错误的概率


假设检验思路
---------------

1. 统计量经过适当转换以后可以变成某种已知的标准分布(正态分布, $t$分布等)
2. 根据标准分布可计算在给定的概率下, 抽样数据可能处于的区间
3. 判断统计量是否位于区间, 如果位于区间则不能拒绝原假设.
4. 否则可以认为统计量位于区间外是小概率事件, 从而认为假设不成立.


P值
--------

P值是在原假设成立的情况下, 出现样本结果或更极端结果的概率. 如果P值很小, 则说明出现这种情况的概率很小, 拒绝原假设的理由就越充分.

例如在双边假设中, 如果设定$\alpha=0.05$, 则当$P>0.025$时就不能拒绝原假设, 反之则可以认为原假设不成立.

> 各类软件都可以比较方便的计算出P值, 将P值与显著水平进行比较就可以简单的判断能否拒绝原假设.


检验问题的说明
----------------

在进行单边检测的时候, 可以自由的选择原命题, 例如可进行左侧检验

$$
H_0: \mu \ge \mu_0
$$

也可以进行右侧检测

$$
H_0: \mu \le \mu_0
$$

但是如果抽样的数据比较接近中间位置, 则可能两个原假设都是无法拒绝的结论.

这并不是一种矛盾的现象, 统计推断并不是一种非此即彼的逻辑. 只有到抽样数据落在拒绝域之中, 才能说有充分的理由想象原假设不成立.

因此在实际问题中, 通常需要根据问题背景合理的选择原假设. 一般将希望证明的假设作为备择假设, 而将原有的, 传统的观点作为原假设. 

因为如果认可原有的结论, 就不需要进行检验了, 只有对原有的结论产生怀疑时, 才会希望通过假设检验来推翻原有的观念.



第六章 分类数据分析
===================


$\chi^2$统计量
-----------------

若用$f_o$表示观察值频数, 用$f_e$表示期望值频数, 则$\chi^2$统计量可以表示为

$$
\chi^2=\sum\frac{(f_o -f_e)^2}{f_e}
$$



拟合优度检验
-------------

拟合优度检验是用$\chi^2$统计量进行统计显著性检验, 用于判断期望频数与观察频数是否具有显著性差异, 从而对分类变量进行分析.

首先假定要检测的数据与理论值不存在显著差异, 然后可通过查表获得指定自由度下给定显著水平的$\chi^2$统计量值.

如果计算结果大于查表的值, 则说明数据偏离预期, 应该拒绝原假设.

> 各类软件可直接完成拟合优度检验, 并给出P值

独立性检验
------------

独立性检验是分析列联表中行变量与列变量是否相互独立. 

其主要思路是先假定两个变量相互独立, 依次计算表格中各个情况下的理论值, 然后使用$\chi^2$统计量判断其是否明显偏离理论值

> 各类软件可直接完成独立性检验, 并给出P值


$\chi^2$分布的期望值准则
-------------------------

$\chi^2$分布进行独立性检验要求样本量足够大, 尤其是每个单元格的期望频数不能过小, 否则$\chi^2$检验可能得到错误的结论. 通常有两条准则

1. 如果只有两个单元, 则每个单元的期望频数必须是5或5以上
2. 如果有多个单元, 则不能有超过20%的单元的期望频数小于5


参考资料与扩展阅读
=========================

一个视频从整体思路上了解统计学的各类基本概念

- [油管百万播放」 统计学入门 | 了解t检验、卡方检验、 p值等](https://www.bilibili.com/video/BV1WG411W7qL/)