---
title: 消息队列学习笔记
math: false
date: 2023-06-01 08:51:28
categories:
tags:
    - Kafka
cover_picture:
---



Kafka消息队列
------------------

### 基本概念

- Producer（生产者）：生产者负责向Kafka集群发送数据消息。生产者可以是应用程序、服务或者其他数据源。
- Consumer（消费者）：消费者订阅并处理来自Kafka集群的数据消息。消费者可以是应用程序、服务或者数据处理系统。
- Broker（代理）：Kafka集群中的每个节点被称为代理。代理在分布式环境中存储和传输消息，确保系统的高可用性和可扩展性。
- Topic（主题）：主题是具有相似数据类型或用途的消息流的逻辑集合。生产者向特定主题发送消息，而消费者订阅特定主题以接收消息。
- Partition（分区）：为了实现高吞吐量和负载均衡，主题被分成多个分区。每个分区都是一个有序、不可改变的消息序列，数据按顺序写入分区并按顺序读取。
- Replication（复制）：为了确保数据的可靠性和容错，分区可以在多个代理上进行复制。这使得在某个代理发生故障时，其他具有相同副本的代理节点可以继续处理消息。
- Offset（偏移量）：偏移量是分区中每条消息的唯一标识。它表示消息在分区中的位置。消费者可以根据偏移量读取特定消息，并追踪已经处理过的数据。
- Consumer Group（消费者组）：消费者组由一组共同订阅一个或多个主题的消费者组成。消费者组内的消费者可以协同处理不同分区的数据，实现负载均衡和消息顺序处理。

> [7张图了解kafka基本概念](https://segmentfault.com/a/1190000040633029)

### 消费组

投递到Kafka的消息可以被多个消费组消费, 每个消费组都会独立地追踪已消费消. Kafka的设计允许多个消费组并行地消费同一个主题. 在一个消费组内, 一个分组仅可被一个消费者消费, 因此分区数量通常应该设置为消费者数量的整数倍, 使得每个消费者消费的分区数量尽可能均衡.

> 对于生产者, 有时还会看到一个名为clientID的参数, 该参数仅用于标识生产者, 对投递消息无影响.


使用Docker镜像安装kafka
-----------------------

使用如下的`docker-compose.yml`文件拉取kafka镜像

```yml
# Copyright VMware, Inc.
# SPDX-License-Identifier: APACHE-2.0

version: "2"

services:
  kafka:
    image: docker.io/bitnami/kafka:3.5
    ports:
      - "9092:9092"
      - '9094:9094'
    volumes:
      - "kafka_data:/bitnami"
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT

volumes:
  kafka_data:
    driver: local
```

> 注意: 官方标准的yml文件中未配置KAFKA_CFG_LISTENERS, 导致无法在HOST机器中链接到镜像内的kafka


可执行如下指令安装python的kafka库

```
pip install confluent-kafka
```

并使用如下脚本验证能否正常发送消息

```py
#! /usr/bin/python3

from confluent_kafka import Producer
import socket

conf = {'bootstrap.servers': "localhost:9092", 'client.id': socket.gethostname()}

producer = Producer(conf)

producer.produce("foo", key="key", value="value")
producer.flush()
```






RabbitMQ和Kafka的对比
------------------------------


RabbitMQ 和 Kafka 都是高度可扩展、高性能的消息队列服务。以下是它们一些基本概念的对比：

数据模型
RabbitMQ：基于 AMQP 协议，使用 Exchange 和 Queue 的概念。生产者发送消息到 Exchange，然后 Exchange 根据规则将消息路由到一个或多个 Queue 中，消费者从 Queue 中消费消息。
Kafka：基于分布式的流处理平台，使用 Topic 和 Partition 的概念。生产者发送消息到特定的 Topic，Topic 可划分为多个 Partition。消费者订阅并消费特定的 Topic。


消息分发
RabbitMQ：通过 Exchange 和 Binding 规则实现较为灵活的消息路由能力。可以实现广播、直接发送或主题匹配等方式来将消息传递给消费者。
Kafka：通过 Partition 实现消息并行处理，从而提升消费速度。但不具备灵活的消息路由功能。


消息持久化
RabbitMQ：消息默认保存在内存中，但可以配置为持久化到硬盘。持久化的消息在 RabbitMQ 服务器重启后仍然可用。
Kafka：消息默认持久化存储在硬盘上。默认保留数据的时间窗口是7天，也可以调整。

消费模型
RabbitMQ：支持点对点模式（一个消息只能被一个消费者消费）以及发布/订阅模式（一个消息可以被多个消费者消费）。
Kafka：天然支持发布/订阅模式，允许多个消费组并行消费同一主题。


一致性
RabbitMQ：在消息传递过程中可能会发生消息丢失或重复消费的情况。
Kafka：通过使用 Partition、Offset 和 Consumer Group 确保消息只会被消费一次，保证了一致性。


扩展性
RabbitMQ：可以通过集群或镜像队列来实现高可用性和负载均衡。
Kafka：采用分布式架构、多副本机制和分区模型，具备较高的扩展性和容错能力。


总结，RabbitMQ 与 Kafka 在概念上存在一定相似度，都提供高性能、高可扩展性的消息队列服务。然而，它们在数据模型、消息分发、持久化和消费模型等方面有着不同的特点。RabbitMQ 更适用于需要灵活路由能力的场景，而 Kafka 更适用于面向高并发、高吞吐量的大规模事件流处理场景。选择适合的消息队列服务需要根据实际业务场景进行评估。