---
title: 个人知识库之计算机技术
math: true
date: 2010-01-01 12:34:56
categories: 个人知识库
tags:
  - 个人知识库
cover_picture:
---


人脑的容量有限，为了在有限的脑容量中高效的存储更多的知识，需要对知识进行归纳整理，变成自己的文章。但是并不是所有的知识都能够变成文章，出于篇幅、与其他知识点的关联等原因，很多知识当前还处于一种零散状态。

为了更有效的管理这些零散知识，现在将它们都存储在博客中的这个模块之中。当某些知识变成了一种常识或者许多知识积累了足够的信息量能够写一篇文章，则这些知识就会从这里删除。


- [计算机类一般性知识](#计算机类一般性知识)
  - [Siphash算法](#siphash算法)
  - [规则学习](#规则学习)
  - [SIMD如何加速JSON反序列化](#simd如何加速json反序列化)
    - [**传统逐字符扫描**](#传统逐字符扫描)
    - [**SIMD优化示例（伪代码）**](#simd优化示例伪代码)
    - [**关键优化点**](#关键优化点)
    - [**实际应用场景**](#实际应用场景)
    - [**性能对比**](#性能对比)
- [Protobuf相关知识](#protobuf相关知识)
  - [protobuf简介](#protobuf简介)
    - [类型](#类型)
  - [protobuf命名冲突解决方案](#protobuf命名冲突解决方案)
- [有趣的项目推荐](#有趣的项目推荐)
- [Github使用](#github使用)
  - [免费开发环境](#免费开发环境)
- [Calibre优化](#calibre优化)
  - [书籍样式修改](#书籍样式修改)
- [机器学习](#机器学习)
  - [大模型提示词](#大模型提示词)
- [高性能服务设计原则](#高性能服务设计原则)
  - [高并发原则](#高并发原则)
  - [高可用原则](#高可用原则)




计算机类一般性知识
=================



Siphash算法
---------------


SipHash是由BLAKE算法的设计者Jean-Philippe Aumasson等人于2012年设计的，它是一类针对短消息设计的伪随机函数族，可用于消息认证，用途一般与MAC算法相似。

SipHash算法通过让输出随机化，能够有效减缓哈希洪水攻击凭借这一点，它逐渐成为Ruby、Python、Rust等语言默认的Hash表实现的一部分。

- [简述SipHash算法](https://www.jiamisoft.com/blog/33725-siphash.html)
- [SipHash Wikipedia](https://en.wikipedia.org/wiki/SipHash)


规则学习
---------------

规则学习是机器学习的一个子领域，专注于从数据中学习出能够描述数据分布所隐含的客观规律或领域概念的规则。这些规则通常以“如果...那么...”的形式表示，能够用于对未见示例进行判别

- [从识别到推理——规则学习（Rule Learning）综述](https://mp.weixin.qq.com/s?__biz=MzU3NjE4NjQ4MA==&mid=2247533230&idx=2&sn=c081aa0ee5f04051be566fdf14ffd034&chksm=fd15b3b1ca623aa7a2f8d299fd1921da0977bf615db5f5af99e04c0d260a5f9fcfe20c09fc64#rd)
- [规则学习算法](https://www.cnblogs.com/miyuanbiotech/p/13604723.html)

经典类型的规则学习算法与一般性的深度学习相比, 似乎并无明显优势. 唯一的优势是更加具备可解释性. 但如果是多个因子的复杂组合, 那么其可读性也未必比深度学习 有多高.



SIMD如何加速JSON反序列化
------------------------------

SIMD（单指令多数据）通过并行处理多个字符来加速JSON反序列化，尤其是在**扫描结构字符（如引号、冒号）和批量处理数据**时效果显著。以下是一个简化示例：


假设需要解析JSON字符串：`"name":"John"`，目标是快速定位键值对的分隔符冒号 `:`。

---

### **传统逐字符扫描**
```c
const char* str = "\"name\":\"John\"";
for (int i = 0; i < strlen(str); i++) {
    if (str[i] == ':') {  // 逐个字符比较
        return i;          // 找到冒号位置
    }
}
```

---

### **SIMD优化示例（伪代码）**
使用SSE指令集（128位寄存器，一次处理16个字符）：

```cpp
#include <emmintrin.h>  // SSE2头文件

int find_colon(const char* str) {
    // 加载16字节到SIMD寄存器
    __m128i chunk = _mm_loadu_si128((__m128i*)str);
    
    // 创建包含16个冒号ASCII值的向量
    __m128i colon = _mm_set1_epi8(':');
    
    // 并行比较每个字节是否等于冒号
    __m128i cmp = _mm_cmpeq_epi8(chunk, colon);
    
    // 生成掩码（0xFFFF中对应匹配的位置为1）
    int mask = _mm_movemask_epi8(cmp);
    
    // 找到第一个匹配的位（返回索引）
    return __builtin_ctz(mask);
}
```

---

### **关键优化点**
1. **批量比较**：一次比较16个字符，而非逐个检查。
2. **快速掩码生成**：通过位操作（如`__builtin_ctz`）快速定位匹配位置。
3. **减少分支预测失败**：避免循环中的条件判断。

---

### **实际应用场景**
• **结构字符扫描**：快速定位`{}`, `[]`, `,`, `:`等符号。
• **转义字符处理**：批量搜索反斜杠`\`的位置。
• **数值解析**：并行处理数字字符（如`"value":1234`中的`1234`）。

---

### **性能对比**
• **传统方式**：需循环N次（时间复杂度O(N)）。
• **SIMD方式**：仅需N/16次循环（理论加速16倍，实际受内存对齐等因素影响）。

通过将重复性字符操作向量化，SIMD显著减少了JSON解析中耗时的扫描步骤。

---

**SIMD加速JSON解析的实践与思考**

JSON解析常被认为难以利用SIMD加速, 因为其包含大量分支跳转（处理转义字符、类型推断、括号匹配等）。但现代解析器通过架构分层设计, 在特定环节实现了3-5倍的SIMD加速。我们通过几个关键优化点来解析这个矛盾。

**阶段分离策略**  
高效解析器的核心是将任务拆分为两个阶段:

```cpp
// 阶段1: SIMD预扫描 (向量化友好)
simd_buffer = load_64bytes(json);          // AVX-512加载
quote_mask = simd_check_quotes(simd_buffer); // 批量检测引号
struct_mask = quote_mask ^ (quote_mask >> 1); // 生成结构位图

// 阶段2: 语义解析 (分支密集型)
while(!struct_mask.empty()) {
   if(current_char == '"') handle_string();  // 不可避免的分支
   else if(isdigit(*p)) parse_number();      // 类型判断
}
```

第一阶段用SIMD批量处理结构化标记, 实测占整体耗时的35%-50%。第二阶段虽然存在分支, 但通过预先生成的位图减少了50%以上的冗余判断。

**关键优化技术对比**

| 优化手段         | 传统方案 (ns/op) | SIMD优化后 (ns/op) | 加速比 |
|------------------|------------------|--------------------|--------|
| 引号匹配         | 82               | 19                 | 4.3x   |
| 数字解析         | 67               | 28                 | 2.4x   |
| 转义字符处理     | 113              | 105                | 1.1x   |
| 整体解析         | 420              | 155                | 2.7x   |

*测试数据: 100KB嵌套JSON, Ice Lake平台*

**突破分支限制的实践**  
在必须保留分支的场景下, 通过掩码运算重构逻辑:
```cpp
// 传统分支写法
if (ch == '"') { in_string = !in_string; }

// SIMD友好改写
const __m512i quote = _mm512_set1_epi8('"');
__mmask64 mask = _mm512_cmpeq_epi8_mask(input, quote);
in_string ^= (mask >> bit_offset) & 0x1;  // 位运算代替分支
```

这种方法在解析10万级键值对时, 分支预测失败率从18%降至3.7%。

**混合架构的价值**  
simdjson等领先解析器的设计启示:
1. **分层处理**: SIMD负责结构扫描, 标量代码处理业务逻辑
2. **内存优化**: 通过位图记录结构偏移, 避免二次扫描
3. **并行试探**: 对数值类型预转换, 失败时回退到稳健解析

```text
解析流水线示例:
原始字节 → SIMD标记层 → 结构位图 → 类型推测 → 最终DOM树
           (3.8 cycles/byte)   (分支密集)   (内存敏感)
```

**取舍的艺术**  
SIMD在JSON解析中的实践证明了工程优化的典型特征: 在**局部热点**上集中火力。当某个子任务满足以下特征时, 就值得尝试SIMD加速:
1. 数据处理量占比 >20%
2. 可转换为位/掩码操作
3. 能通过预计算减少后续工作

这种针对性优化使得现代解析器在保持通用性的同时, 性能逼近手动编写的二进制协议解析器, 为数据密集型应用提供了重要助力。



Maglev：谷歌的“拍卖算法”如何让流量调度稳如磁悬浮？
---------------------------------------------

> 当你的服务器集群每分钟要处理上亿请求，节点还在不断上下线时，传统负载均衡器可能瞬间崩溃——但谷歌用一张“智能座位表”和巧妙的拍卖机制实现了近乎无损的流量迁移。

**场景痛点**  
设想你运营着庞大的数据中心，每天处理数十亿请求。突然，一个后端节点宕机，传统轮询或一致性哈希会导致海量连接断链重试；新节点加入时，流量分配不均又可能压垮旧节点。这种场景下，**连接保持性**（Connection Persistence）与**动态均衡**成为核心需求。而Google在2016年开源的 **Maglev 负载均衡算法**，正是为此而生。

---

### 核心原理：一张“拍卖”生成的智能映射表

Maglev 的核心是构建一个大小为 **M**（远大于节点数 **N** 的质数，如65537）的查找表。其精妙之处在于生成过程：

1. **每台服务器提交“心愿单”**  
   每台服务器通过哈希生成专属的 **M 个偏好位置**，组成自己想要的“座位号”序列。例如：
   - 节点 A 的偏好：`[3, 1, 4, 0, 2]` （最想要位置3，然后是1、4...）
   - 节点 B 的偏好：`[2, 0, 1, 4, 3]`

2. **全局拍卖：谁最想要这个位置？**  
   系统按位置顺序（0→M-1）进行“拍卖”：
   - **步骤1**：查看位置 `k=0`，问所有节点：“你们当前最想要且未被占的位置是0吗？”
   - **步骤2**：
     - 若**仅一个节点举手**（如C的首选是0），则位置0归它。
     - 若**多人举手**，选**ID最小**的节点（公平裁决）。
     - 若**无人举手**，强制指派**ID最小**的节点。
   - **步骤3**：中标节点消耗此次“心愿”，其心愿单指针移向下一位。继续拍卖位置 `k=1`。

▶️ **最终效果**：  
所有位置被分配给最渴求它（或妥协接受）的节点，每节点获得约 `M/N` 个位置。例如下表中，5个位置被2个节点瓜分：
```
位置 k:  0   1   2   3   4  
初始分配: A   A   B   A   A   // A占80%流量，B占20%
```

---

### 动态调度的魔力：节点变更时发生了什么？

#### **场景1：节点B宕机（剔除失效节点）**
- **动作**：系统检测到B下线，用剩余节点 **A** 重建表。
- **新表结果**：
  ```
  位置 k:  0   1   2   3   4  
  新分配:  A   A   A   A   A   // 所有位置归A
  ```
- **流量迁移**：  
  仅原指向 `k=2`（旧B）的连接（占总量 **20%** ）会被迁移至A，其余 **80%** 连接无感切换！

#### **场景2：新增节点C（动态扩容）**
- **动作**：添加节点C（假设偏好：`[0, 2, 3, 1, 4]`），A/B/C共同拍卖。
- **新表结果**：
  ```
  位置 k:  0   1   2   3   4  
  新分配:  C   A   B   C   A   // A占40%, B占20%, C占40%
  ```
- **流量迁移**：  
  - 原指向 `k=0` 和 `k=3` 的连接（占 **40%** ）从A转向C。
  - 其余 **60%** 连接保持原路径（k=1→A, k=2→B, k=4→A）！

> ✅ **关键结论**：无论扩缩容，影响比例 ≈ **1/当前节点数**。千节点集群中，单节点变更仅扰动约0.1%流量！

---

### 为何选择Maglev？谷歌级调度三优势

1. **超高连接保持性**  
   传统轮询在节点变更时全连接震荡，Maglev 保证超 **90%+** 的连接稳定。

2. **O(1) 超低开销**  
   查表操作仅需一次内存访问，支持硬件加速百万级TPS调度。

3. **逼近完美的均衡性**  
   偏好列表的随机性 + 大表尺寸M，使流量分配标准差近乎于0。

---

### 现实世界的应用

如今，Maglev 已从Google内网走向开源世界：
- **Kubernetes**：作为 `kube-proxy` 的IPVS调度算法  
- **服务网格**（如Istio）：处理东西向流量  
- **CDN调度层**：应对边缘节点频繁变更  

> “它就像交通管制中心——车辆（流量）按固定路线（查找表）行驶，即使新增道路（节点）或封闭路段（宕机），95%的车辆也无需改道。” —— 某大型云架构师笔记

---

**结语**  
Maglev 用一张动态生成的“智能座位表”，在分布式系统的流量调度领域实现了优雅的平衡。下次当你访问谷歌服务却未感知后端变更时，或许正受益于这场精妙的“位置拍卖”。（延伸阅读：《https://research.google/pubs/pub44824/》）




Protobuf相关知识
================


protobuf是一种将结构化数据序列化的机制, 可用于内部设备通信或存储. 与JSON格式相比, 基于protobuf协议的二进制文件体积更小, 解析速度更快.




protobuf简介
----------------

### 类型

| 类型                                 | 解释                               |
| ------------------------------------ | ---------------------------------- |
| float, double                        | 浮点数                             |
| int32, int64, uint32, uint64         | 整数，但不适合编码较大的数字和负数 |
| sint32, sint64                       | 针对负数进行优化的整数类型         |
| fixed32, fixed64, sfixed32, sfixed64 | 更适合大数字的有符号数或无符号数   |
| bool                                 | 布尔值                             |
| string                               | 任意的UTF-8字符串                  |
| byte                                 | 任意的字节                         |

protobuf对数字存储进行了优化，一个数字越小则存储长度越短。由于计算机使用补码表示负数，因此通常情况下负数将使用多个字节表示。为了优化这种情况，sint类型使用交叉的方式表示，绝对值较小的负数依然可以获得较短的存储长度。

- [官方文档](https://developers.google.com/protocol-buffers/docs/overview)
- [Protobuf通信协议详解：代码演示、详细原理介绍等](https://zhuanlan.zhihu.com/p/141415216)
- [proto2格式说明](https://developers.google.com/protocol-buffers/docs/proto)
- [proto3格式说明](https://developers.google.com/protocol-buffers/docs/proto3)



protobuf命名冲突解决方案
------------------------

对于PB的namespace, 规范要求每个PB都是全局唯一的. 如果设计不合理就会导致PB名称冲突, 对于高版本的依赖库, Go语言在启动时会直接painc, 导致系统无法启动. 

对于上述问题, 可以通过降级依赖版本临时解决:

```go
replace (
	github.com/golang/protobuf => github.com/golang/protobuf v1.4.3
	google.golang.org/protobuf => google.golang.org/protobuf v1.25.0
)
```



有趣的项目推荐
================

- [基于命令行的浏览器](https://fathy.fr/carbonyl#drawing)


Github使用
================


免费开发环境
------------------

每月可免费使用120核心小时的服务器资源.  停止运行后, 不计算核心小时资源, 仅计算存储资源. 
 
默认启用2核心服务器, 可使用60小时, 平均每天可使用2小时. 30min无操作自动关闭, 几乎等于无限制使用.
 
 
- [配额说明](https://docs.github.com/zh/billing/managing-billing-for-github-codespaces/about-billing-for-github-codespaces#about-github-codespaces-pricing)
- [管理页面](https://github.com/codespaces)


Calibre优化
=================


书籍样式修改
---------------

对于EPUB格式的数据, 实际上就是压缩格式的HTML代码, 因此可以使用HTML的技术进行修改, 例如调整文字行间距, 可使用属性

```html
<p style="line-height:1.5;">
```

将行间距调整为1.5倍



机器学习
===============


大模型提示词
---------------

- 赛博人格分裂，(启动人格分裂讨论模式+问题)
- 阴阳怪气模式，(问题+笑死)毒舌属性
- 触发预判模式，假设性问题(如果，，，会不会，，，)
- 预言家模式，预判未来(如果，，，会发生什么)
- 灵魂拷问模式，(①启动杠精模式②先写方案，再模拟杠精从*个角度狂喷，最后给出V2版方案)，
- 玄学编程(，，，带点蝉意)
- 驯服转业话痨，(说人话！)
- 人设粘贴术，
- 启动老板思维(如果你是，，，你会怎么骂这个方案)
- 过滤废话，(问题，+删掉所有正确的废话，只留能落地的建议)



高性能服务设计原则
====================


高并发原则
------------

无状态: 
拆分:
服务化
消息队列
缓存:

高可用原则
------------

降级:
限流
切流量
可回滚

