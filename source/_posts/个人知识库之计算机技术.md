---
title: 个人知识库之计算机技术
math: true
date: 2010-01-01 12:34:56
categories: 个人知识库
tags:
  - 个人知识库
  - Java
  - Go
  - 数据库
cover_picture:
---


人脑的容量有限，为了在有限的脑容量中高效的存储更多的知识，需要对知识进行归纳整理，变成自己的文章。但是并不是所有的知识都能够变成文章，出于篇幅、与其他知识点的关联等原因，很多知识当前还处于一种零散状态。

为了更有效的管理这些零散知识，现在将它们都存储在博客中的这个模块之中。当某些知识变成了一种常识或者许多知识积累了足够的信息量能够写一篇文章，则这些知识就会从这里删除。


- [计算机类一般性知识](#计算机类一般性知识)
  - [Sqlite显示表头](#sqlite显示表头)
  - [Siphash算法](#siphash算法)
  - [规则学习](#规则学习)
  - [SSH隧道](#ssh隧道)
- [Protobuf相关知识](#protobuf相关知识)
  - [protobuf简介](#protobuf简介)
    - [类型](#类型)
  - [protobuf命名冲突解决方案](#protobuf命名冲突解决方案)
- [有趣的项目推荐](#有趣的项目推荐)
- [Github使用](#github使用)
  - [免费开发环境](#免费开发环境)
- [Calibre优化](#calibre优化)
  - [书籍样式修改](#书籍样式修改)
- [机器学习](#机器学习)
  - [模型蒸馏](#模型蒸馏)
    - [为什么知识蒸馏是有效的](#为什么知识蒸馏是有效的)
- [高性能服务设计原则](#高性能服务设计原则)
  - [高并发原则](#高并发原则)
  - [高可用原则](#高可用原则)




计算机类一般性知识
=================

Sqlite显示表头
-----------------

默认情况下执行select语句只能得到`|`分割的数据, 如果数据比较多, 这种格式就不够直观. 可以通过如下的指令启用表头和以行模式展示数据.

```
.head on
.mode column
```

Siphash算法
---------------


SipHash是由BLAKE算法的设计者Jean-Philippe Aumasson等人于2012年设计的，它是一类针对短消息设计的伪随机函数族，可用于消息认证，用途一般与MAC算法相似。

SipHash算法通过让输出随机化，能够有效减缓哈希洪水攻击凭借这一点，它逐渐成为Ruby、Python、Rust等语言默认的Hash表实现的一部分。

- [简述SipHash算法](https://www.jiamisoft.com/blog/33725-siphash.html)
- [SipHash Wikipedia](https://en.wikipedia.org/wiki/SipHash)


规则学习
---------------

规则学习是机器学习的一个子领域，专注于从数据中学习出能够描述数据分布所隐含的客观规律或领域概念的规则。这些规则通常以“如果...那么...”的形式表示，能够用于对未见示例进行判别

- [从识别到推理——规则学习（Rule Learning）综述](https://mp.weixin.qq.com/s?__biz=MzU3NjE4NjQ4MA==&mid=2247533230&idx=2&sn=c081aa0ee5f04051be566fdf14ffd034&chksm=fd15b3b1ca623aa7a2f8d299fd1921da0977bf615db5f5af99e04c0d260a5f9fcfe20c09fc64#rd)
- [规则学习算法](https://www.cnblogs.com/miyuanbiotech/p/13604723.html)

经典类型的规则学习算法与一般性的深度学习相比, 似乎并无明显优势. 唯一的优势是更加具备可解释性. 但如果是多个因子的复杂组合, 那么其可读性也未必比深度学习 有多高.



SSH隧道
--------------------

- [SSH隧道：端口转发功能详解 ](https://www.cnblogs.com/f-ck-need-u/p/10482832.html)





Protobuf相关知识
================


protobuf是一种将结构化数据序列化的机制, 可用于内部设备通信或存储. 与JSON格式相比, 基于protobuf协议的二进制文件体积更小, 解析速度更快.




protobuf简介
----------------

### 类型

| 类型                                 | 解释                               |
| ------------------------------------ | ---------------------------------- |
| float, double                        | 浮点数                             |
| int32, int64, uint32, uint64         | 整数，但不适合编码较大的数字和负数 |
| sint32, sint64                       | 针对负数进行优化的整数类型         |
| fixed32, fixed64, sfixed32, sfixed64 | 更适合大数字的有符号数或无符号数   |
| bool                                 | 布尔值                             |
| string                               | 任意的UTF-8字符串                  |
| byte                                 | 任意的字节                         |

protobuf对数字存储进行了优化，一个数字越小则存储长度越短。由于计算机使用补码表示负数，因此通常情况下负数将使用多个字节表示。为了优化这种情况，sint类型使用交叉的方式表示，绝对值较小的负数依然可以获得较短的存储长度。

- [官方文档](https://developers.google.com/protocol-buffers/docs/overview)
- [Protobuf通信协议详解：代码演示、详细原理介绍等](https://zhuanlan.zhihu.com/p/141415216)
- [proto2格式说明](https://developers.google.com/protocol-buffers/docs/proto)
- [proto3格式说明](https://developers.google.com/protocol-buffers/docs/proto3)



protobuf命名冲突解决方案
------------------------

对于PB的namespace, 规范要求每个PB都是全局唯一的. 如果设计不合理就会导致PB名称冲突, 对于高版本的依赖库, Go语言在启动时会直接painc, 导致系统无法启动. 

对于上述问题, 可以通过降级依赖版本临时解决:

```go
replace (
	github.com/golang/protobuf => github.com/golang/protobuf v1.4.3
	google.golang.org/protobuf => google.golang.org/protobuf v1.25.0
)
```



有趣的项目推荐
================

- [基于命令行的浏览器](https://fathy.fr/carbonyl#drawing)


Github使用
================


免费开发环境
------------------

每月可免费使用120核心小时的服务器资源.  停止运行后, 不计算核心小时资源, 仅计算存储资源. 
 
默认启用2核心服务器, 可使用60小时, 平均每天可使用2小时. 30min无操作自动关闭, 几乎等于无限制使用.
 
 
- [配额说明](https://docs.github.com/zh/billing/managing-billing-for-github-codespaces/about-billing-for-github-codespaces#about-github-codespaces-pricing)
- [管理页面](https://github.com/codespaces)


Calibre优化
=================


书籍样式修改
---------------

对于EPUB格式的数据, 实际上就是压缩格式的HTML代码, 因此可以使用HTML的技术进行修改, 例如调整文字行间距, 可使用属性

```html
<p style="line-height:1.5;">
```

将行间距调整为1.5倍



机器学习
===============


模型蒸馏
-----------

模型蒸馏是将大型AI模型（教师模型）的知识蒸馏（Distillation）到小型模型（学生模型）的过程，旨在通过迁移知识使小模型在保持较低计算资源需求的同时，尽可能接近大模型的性能。

首先训练一个高性能的大模型（如BERT、GPT等），作为知识提供者。此训练过程是标准的模型训练过程（监督学习）。然后设计一个参数更少、结构更简单的小模型（如TinyBERT、DistilBERT等）。学生模型结构需与教师模型兼容（例如，层数减少但维度对齐）。通过简化架构（减少层数、注意力头数）、量化或剪枝降低计算成本。

---

蒸馏的关键是让学生模型模仿教师模型的输出，通常通过以下两种损失函数结合实现：

**（1）软目标损失（Soft Target Loss）**: 教师模型通过提高“温度”参数 \( T \)（\( T > 1 \)）软化输出概率分布，使不同类别的概率差异更平滑（例如，将原始logits除以 \( T \) 后再做Softmax）。学生模型在相同温度下输出概率，并与教师模型的软化概率计算损失（如KL散度）。

$$
\mathcal{L}_{\text{soft}} = \text{KL}\left( \sigma\left(\frac{\mathbf{z}_{\text{teacher}}}{T}\right) \parallel \sigma\left(\frac{\mathbf{z}_{\text{student}}}{T}\right) \right)
$$

其中 \( \sigma \) 是Softmax函数，\( \mathbf{z} \) 为模型输出的logits。

> 如何理解温度的作用? 实际上就是把每个神经元输出同时缩小相同的倍数, 那么经过softmax处理后相对的差距就会缩小. 例如可以考虑T为无穷大时, 最终输出将会是一个均匀分布. 因此温度操作通常可视为对输出进行"平滑"或者"软化"

**（2）硬目标损失（Hard Target Loss）**: 学生模型还需直接学习真实标签（Ground Truth），通常用交叉熵损失：

$$
\mathcal{L}_{\text{hard}} = \text{CrossEntropy}(y_{\text{true}}, \mathbf{z}_{\text{student}})
$$


**总损失函数**: 综合两者，通过权重系数 \( \lambda \) 平衡：

$$
\mathcal{L}_{\text{total}} = \lambda \cdot \mathcal{L}_{\text{soft}} + (1 - \lambda) \cdot \mathcal{L}_{\text{hard}}
$$

> 这个$\lambda$可以说是机器学习味道最浓郁的部分


---


### 为什么知识蒸馏是有效的

1. 信息熵视角: 高温软化后的分布具有更高的熵（不确定性），传递了更多信息，而低熵分布（如硬标签）信息量较少。知识蒸馏的本质是通过最大化教师模型输出的熵来传递更多知识。
2. 梯度匹配理论: 学生模型通过匹配教师模型的梯度方向（而非仅输出值）来学习，高温软化后的分布能提供更稳定的梯度信号，避免陷入局部最优。

> 用信息熵来解释, 确实是有点数学理论.

学生模型通过拟合高温软化后的分布，不仅能学到“猫”是正确类别，还能理解“豹”比“卡车”更接近正确答案。这种隐含的类别相似性知识，显著提升了小模型的泛化能力。蒸馏后的小模型不仅能“知其然”（预测结果），还能“知其所以然”（类别间的推理逻辑），最终在轻量化的同时保持高性能。

---------

此外, 除了在最初输出层对齐结果外, 还可以在中间层对齐, 例如强迫学生模型的中间层特征（如注意力矩阵、隐藏状态）与教师模型对齐（如FitNets、TinyBERT）。这些中间层包含了许多隐含的知识, 而采取一般的训练方法很难是学生模型获取到这类知识.




高性能服务设计原则
====================


高并发原则
------------

无状态: 
拆分:
服务化
消息队列
缓存:

高可用原则
------------

降级:
限流
切流量
可回滚
