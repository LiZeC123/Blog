---
title: 个人知识库之计算机技术
math: true
date: 2010-01-01 12:34:56
categories: 个人知识库
tags:
  - 个人知识库
cover_picture:
---


人脑的容量有限，为了在有限的脑容量中高效的存储更多的知识，需要对知识进行归纳整理，变成自己的文章。但是并不是所有的知识都能够变成文章，出于篇幅、与其他知识点的关联等原因，很多知识当前还处于一种零散状态。

为了更有效的管理这些零散知识，现在将它们都存储在博客中的这个模块之中。当某些知识变成了一种常识或者许多知识积累了足够的信息量能够写一篇文章，则这些知识就会从这里删除。


- [计算机类一般性知识](#计算机类一般性知识)
  - [Mac开发环境](#mac开发环境)
    - [Ubuntu环境](#ubuntu环境)
    - [依赖配置](#依赖配置)
  - [Siphash算法](#siphash算法)
  - [规则学习](#规则学习)
  - [SIMD如何加速JSON反序列化](#simd如何加速json反序列化)
    - [**传统逐字符扫描**](#传统逐字符扫描)
    - [**SIMD优化示例（伪代码）**](#simd优化示例伪代码)
    - [**关键优化点**](#关键优化点)
    - [**实际应用场景**](#实际应用场景)
    - [**性能对比**](#性能对比)
  - [Maglev：谷歌的“拍卖算法”如何让流量调度稳如磁悬浮？](#maglev谷歌的拍卖算法如何让流量调度稳如磁悬浮)
    - [核心原理：一张“拍卖”生成的智能映射表](#核心原理一张拍卖生成的智能映射表)
    - [动态调度的魔力：节点变更时发生了什么？](#动态调度的魔力节点变更时发生了什么)
      - [**场景1：节点B宕机（剔除失效节点）**](#场景1节点b宕机剔除失效节点)
      - [**场景2：新增节点C（动态扩容）**](#场景2新增节点c动态扩容)
    - [为何选择Maglev？谷歌级调度三优势](#为何选择maglev谷歌级调度三优势)
    - [现实世界的应用](#现实世界的应用)
  - [为什么加密过程需要使用动态盐](#为什么加密过程需要使用动态盐)
  - [查看DNS服务的IP地址](#查看dns服务的ip地址)
  - [编译器如何帮助CPU更好的实现分支预测](#编译器如何帮助cpu更好的实现分支预测)
- [Protobuf相关知识](#protobuf相关知识)
  - [protobuf简介](#protobuf简介)
    - [类型](#类型)
  - [protobuf命名冲突解决方案](#protobuf命名冲突解决方案)
  - [Protocol Buffers (PB) 的设计哲学与反序列化安全](#protocol-buffers-pb-的设计哲学与反序列化安全)
- [有趣的项目推荐](#有趣的项目推荐)
- [Github使用](#github使用)
  - [免费开发环境](#免费开发环境)
- [Calibre优化](#calibre优化)
  - [书籍样式修改](#书籍样式修改)
- [机器学习](#机器学习)
  - [大模型提示词](#大模型提示词)
- [高性能服务设计原则](#高性能服务设计原则)




计算机类一般性知识
=================

Mac开发环境
--------------

### Ubuntu环境

对于Mac平台, 可以通过[multipass](https://canonical.com/multipass/install)创建一个Ubuntu虚拟机, 然后在虚拟机内安装和测试一些软件. 这一操作类似于Docker的容器, 如果玩坏了可以快速重新创建镜像. 虽然绝大部分项目也可以在Mac上编译和运行, 但Ubuntu具有更好的通用性. 而且在虚拟机内操作无需考虑依赖冲突问题, 可确保mac本身更稳定.

注意: 实际上, 由于multipass不支持创建镜像, 因此不建议在虚拟机内执行太多初始化指令. 可考虑把大部分操作在宿主机完成, 然后将项目挂载到虚拟机之中. 例如直接在宿主机执行Git操作, 从而在虚拟机内不需要再配置ssh.

基于docker或者podman的方案属于虚拟机套虚拟机, 配置过于复杂, 不推荐使用该方案.


### 依赖配置

1. 能手动安装的全部手动安装. 下载安装包只需要浏览器能正常访问即可, 依赖最小.
2. 能直接代理搞定的就直接代理搞定, 配置代理通常无需复杂配置, 要么成功要么失败, 能够快速获得结果
3. 任何使用都不要使用brew, 配置镜像也无法解决强制依赖github的问题, 配置代理也可能无法连接, 纯纯浪费时间. 有这折腾的时间, 自己手动编译都搞完了.




Siphash算法
---------------


SipHash是由BLAKE算法的设计者Jean-Philippe Aumasson等人于2012年设计的，它是一类针对短消息设计的伪随机函数族，可用于消息认证，用途一般与MAC算法相似。

SipHash算法通过让输出随机化，能够有效减缓哈希洪水攻击凭借这一点，它逐渐成为Ruby、Python、Rust等语言默认的Hash表实现的一部分。

- [简述SipHash算法](https://www.jiamisoft.com/blog/33725-siphash.html)
- [SipHash Wikipedia](https://en.wikipedia.org/wiki/SipHash)


规则学习
---------------

规则学习是机器学习的一个子领域，专注于从数据中学习出能够描述数据分布所隐含的客观规律或领域概念的规则。这些规则通常以“如果...那么...”的形式表示，能够用于对未见示例进行判别

- [从识别到推理——规则学习（Rule Learning）综述](https://mp.weixin.qq.com/s?__biz=MzU3NjE4NjQ4MA==&mid=2247533230&idx=2&sn=c081aa0ee5f04051be566fdf14ffd034&chksm=fd15b3b1ca623aa7a2f8d299fd1921da0977bf615db5f5af99e04c0d260a5f9fcfe20c09fc64#rd)
- [规则学习算法](https://www.cnblogs.com/miyuanbiotech/p/13604723.html)

经典类型的规则学习算法与一般性的深度学习相比, 似乎并无明显优势. 唯一的优势是更加具备可解释性. 但如果是多个因子的复杂组合, 那么其可读性也未必比深度学习 有多高.



SIMD如何加速JSON反序列化
------------------------------

SIMD（单指令多数据）通过并行处理多个字符来加速JSON反序列化，尤其是在**扫描结构字符（如引号、冒号）和批量处理数据**时效果显著。以下是一个简化示例：


假设需要解析JSON字符串：`"name":"John"`，目标是快速定位键值对的分隔符冒号 `:`。

---

### **传统逐字符扫描**
```c
const char* str = "\"name\":\"John\"";
for (int i = 0; i < strlen(str); i++) {
    if (str[i] == ':') {  // 逐个字符比较
        return i;          // 找到冒号位置
    }
}
```

---

### **SIMD优化示例（伪代码）**
使用SSE指令集（128位寄存器，一次处理16个字符）：

```cpp
#include <emmintrin.h>  // SSE2头文件

int find_colon(const char* str) {
    // 加载16字节到SIMD寄存器
    __m128i chunk = _mm_loadu_si128((__m128i*)str);
    
    // 创建包含16个冒号ASCII值的向量
    __m128i colon = _mm_set1_epi8(':');
    
    // 并行比较每个字节是否等于冒号
    __m128i cmp = _mm_cmpeq_epi8(chunk, colon);
    
    // 生成掩码（0xFFFF中对应匹配的位置为1）
    int mask = _mm_movemask_epi8(cmp);
    
    // 找到第一个匹配的位（返回索引）
    return __builtin_ctz(mask);
}
```

---

### **关键优化点**
1. **批量比较**：一次比较16个字符，而非逐个检查。
2. **快速掩码生成**：通过位操作（如`__builtin_ctz`）快速定位匹配位置。
3. **减少分支预测失败**：避免循环中的条件判断。

---

### **实际应用场景**
• **结构字符扫描**：快速定位`{}`, `[]`, `,`, `:`等符号。
• **转义字符处理**：批量搜索反斜杠`\`的位置。
• **数值解析**：并行处理数字字符（如`"value":1234`中的`1234`）。

---

### **性能对比**
• **传统方式**：需循环N次（时间复杂度O(N)）。
• **SIMD方式**：仅需N/16次循环（理论加速16倍，实际受内存对齐等因素影响）。

通过将重复性字符操作向量化，SIMD显著减少了JSON解析中耗时的扫描步骤。

---

**SIMD加速JSON解析的实践与思考**

JSON解析常被认为难以利用SIMD加速, 因为其包含大量分支跳转（处理转义字符、类型推断、括号匹配等）。但现代解析器通过架构分层设计, 在特定环节实现了3-5倍的SIMD加速。我们通过几个关键优化点来解析这个矛盾。

**阶段分离策略**  
高效解析器的核心是将任务拆分为两个阶段:

```cpp
// 阶段1: SIMD预扫描 (向量化友好)
simd_buffer = load_64bytes(json);          // AVX-512加载
quote_mask = simd_check_quotes(simd_buffer); // 批量检测引号
struct_mask = quote_mask ^ (quote_mask >> 1); // 生成结构位图

// 阶段2: 语义解析 (分支密集型)
while(!struct_mask.empty()) {
   if(current_char == '"') handle_string();  // 不可避免的分支
   else if(isdigit(*p)) parse_number();      // 类型判断
}
```

第一阶段用SIMD批量处理结构化标记, 实测占整体耗时的35%-50%。第二阶段虽然存在分支, 但通过预先生成的位图减少了50%以上的冗余判断。

**关键优化技术对比**

| 优化手段         | 传统方案 (ns/op) | SIMD优化后 (ns/op) | 加速比 |
|------------------|------------------|--------------------|--------|
| 引号匹配         | 82               | 19                 | 4.3x   |
| 数字解析         | 67               | 28                 | 2.4x   |
| 转义字符处理     | 113              | 105                | 1.1x   |
| 整体解析         | 420              | 155                | 2.7x   |

*测试数据: 100KB嵌套JSON, Ice Lake平台*

**突破分支限制的实践**  
在必须保留分支的场景下, 通过掩码运算重构逻辑:
```cpp
// 传统分支写法
if (ch == '"') { in_string = !in_string; }

// SIMD友好改写
const __m512i quote = _mm512_set1_epi8('"');
__mmask64 mask = _mm512_cmpeq_epi8_mask(input, quote);
in_string ^= (mask >> bit_offset) & 0x1;  // 位运算代替分支
```

这种方法在解析10万级键值对时, 分支预测失败率从18%降至3.7%。

**混合架构的价值**  
simdjson等领先解析器的设计启示:
1. **分层处理**: SIMD负责结构扫描, 标量代码处理业务逻辑
2. **内存优化**: 通过位图记录结构偏移, 避免二次扫描
3. **并行试探**: 对数值类型预转换, 失败时回退到稳健解析

```text
解析流水线示例:
原始字节 → SIMD标记层 → 结构位图 → 类型推测 → 最终DOM树
           (3.8 cycles/byte)   (分支密集)   (内存敏感)
```

**取舍的艺术**  
SIMD在JSON解析中的实践证明了工程优化的典型特征: 在**局部热点**上集中火力。当某个子任务满足以下特征时, 就值得尝试SIMD加速:
1. 数据处理量占比 >20%
2. 可转换为位/掩码操作
3. 能通过预计算减少后续工作

这种针对性优化使得现代解析器在保持通用性的同时, 性能逼近手动编写的二进制协议解析器, 为数据密集型应用提供了重要助力。



Maglev：谷歌的“拍卖算法”如何让流量调度稳如磁悬浮？
---------------------------------------------

> 当你的服务器集群每分钟要处理上亿请求，节点还在不断上下线时，传统负载均衡器可能瞬间崩溃——但谷歌用一张“智能座位表”和巧妙的拍卖机制实现了近乎无损的流量迁移。

**场景痛点**  
设想你运营着庞大的数据中心，每天处理数十亿请求。突然，一个后端节点宕机，传统轮询或一致性哈希会导致海量连接断链重试；新节点加入时，流量分配不均又可能压垮旧节点。这种场景下，**连接保持性**（Connection Persistence）与**动态均衡**成为核心需求。而Google在2016年开源的 **Maglev 负载均衡算法**，正是为此而生。

---

### 核心原理：一张“拍卖”生成的智能映射表

Maglev 的核心是构建一个大小为 **M**（远大于节点数 **N** 的质数，如65537）的查找表。其精妙之处在于生成过程：

1. **每台服务器提交“心愿单”**  
   每台服务器通过哈希生成专属的 **M 个偏好位置**，组成自己想要的“座位号”序列。例如：
   - 节点 A 的偏好：`[3, 1, 4, 0, 2]` （最想要位置3，然后是1、4...）
   - 节点 B 的偏好：`[2, 0, 1, 4, 3]`

2. **全局拍卖：谁最想要这个位置？**  
   系统按位置顺序（0→M-1）进行“拍卖”：
   - **步骤1**：查看位置 `k=0`，问所有节点：“你们当前最想要且未被占的位置是0吗？”
   - **步骤2**：
     - 若**仅一个节点举手**（如C的首选是0），则位置0归它。
     - 若**多人举手**，选**ID最小**的节点（公平裁决）。
     - 若**无人举手**，强制指派**ID最小**的节点。
   - **步骤3**：中标节点消耗此次“心愿”，其心愿单指针移向下一位。继续拍卖位置 `k=1`。

▶️ **最终效果**：  
所有位置被分配给最渴求它（或妥协接受）的节点，每节点获得约 `M/N` 个位置。例如下表中，5个位置被2个节点瓜分：
```
位置 k:  0   1   2   3   4  
初始分配: A   A   B   A   A   // A占80%流量，B占20%
```

---

### 动态调度的魔力：节点变更时发生了什么？

#### **场景1：节点B宕机（剔除失效节点）**
- **动作**：系统检测到B下线，用剩余节点 **A** 重建表。
- **新表结果**：
  ```
  位置 k:  0   1   2   3   4  
  新分配:  A   A   A   A   A   // 所有位置归A
  ```
- **流量迁移**：  
  仅原指向 `k=2`（旧B）的连接（占总量 **20%** ）会被迁移至A，其余 **80%** 连接无感切换！

#### **场景2：新增节点C（动态扩容）**
- **动作**：添加节点C（假设偏好：`[0, 2, 3, 1, 4]`），A/B/C共同拍卖。
- **新表结果**：
  ```
  位置 k:  0   1   2   3   4  
  新分配:  C   A   B   C   A   // A占40%, B占20%, C占40%
  ```
- **流量迁移**：  
  - 原指向 `k=0` 和 `k=3` 的连接（占 **40%** ）从A转向C。
  - 其余 **60%** 连接保持原路径（k=1→A, k=2→B, k=4→A）！

> ✅ **关键结论**：无论扩缩容，影响比例 ≈ **1/当前节点数**。千节点集群中，单节点变更仅扰动约0.1%流量！

---

### 为何选择Maglev？谷歌级调度三优势

1. **超高连接保持性**  
   传统轮询在节点变更时全连接震荡，Maglev 保证超 **90%+** 的连接稳定。

2. **O(1) 超低开销**  
   查表操作仅需一次内存访问，支持硬件加速百万级TPS调度。

3. **逼近完美的均衡性**  
   偏好列表的随机性 + 大表尺寸M，使流量分配标准差近乎于0。

---

### 现实世界的应用

如今，Maglev 已从Google内网走向开源世界：
- **Kubernetes**：作为 `kube-proxy` 的IPVS调度算法  
- **服务网格**（如Istio）：处理东西向流量  
- **CDN调度层**：应对边缘节点频繁变更  

> “它就像交通管制中心——车辆（流量）按固定路线（查找表）行驶，即使新增道路（节点）或封闭路段（宕机），95%的车辆也无需改道。” —— 某大型云架构师笔记

---

**结语**  
Maglev 用一张动态生成的“智能座位表”，在分布式系统的流量调度领域实现了优雅的平衡。下次当你访问谷歌服务却未感知后端变更时，或许正受益于这场精妙的“位置拍卖”。（延伸阅读：《https://research.google/pubs/pub44824/》）




为什么加密过程需要使用动态盐
---------------------------

在加密系统中使用**动态盐**（每次加密随机生成的新盐）的核心原因在于它从根本上改变了攻击者的破解策略和成本模型。盐的核心使命并非保密，而是**确保唯一性**和**打破预计算**。想象一下，如果所有用户使用相同的密码“123456”，在无盐或固定盐的情况下，这些密码生成的加密密钥是完全相同的。攻击者只需针对这个单一密钥进行破解，一旦成功，所有使用该密码的账户都将沦陷。更危险的是，攻击者可以预先计算一个庞大的“密码->密钥”彩虹表，实现秒级破解。

动态盐的引入彻底瓦解了这种攻击路径。每次加密时，系统都会生成一个全新的、随机的盐值（通常16字节或更长）。即使两个用户拥有完全相同的密码，由于盐值不同，经过密钥派生函数（如PBKDF2、scrypt）处理后，产生的实际加密密钥也截然不同。这意味着：

1.  **预计算攻击失效**：攻击者无法预先计算彩虹表，因为每个加密实例使用的盐都是随机的、唯一的。为破解一个账户准备的表格对另一个账户完全无效。
2.  **批量破解成本激增**：攻击者必须为*每一个目标*单独进行暴力破解。破解100个账户的成本不再是破解1个账户的100倍，而是可能高出数千倍（因为每个目标都需要独立的计算过程）。
3.  **密钥重用风险归零**：即使某个特定“密码+盐”组合被破解，也不会泄露其他使用相同密码但不同盐值的账户。

**那么，为什么盐不需要保密？** 这看似违反直觉，实则蕴含着密码学的智慧：

1.  **盐的使命是“差异化”，而非“隐蔽”**：盐的核心价值在于其**随机性和唯一性**，而不是它的秘密性。它的存在是为了确保相同的输入（密码）产生不同的输出（密钥）。即使攻击者知道盐值（例如从存储中读取），他们仍然需要：
    *   针对*这个特定的盐值*
    *   对*可能的密码空间*
    *   进行*完整的暴力破解或字典攻击*
    这极大地增加了攻击的边际成本。
2.  **遵循Kerckhoffs原则**：现代密码学的安全应建立在**算法和密钥的保密性**上，而不是系统的晦涩性（如隐藏盐）。公开盐值符合这一原则，让安全评估更透明。
3.  **实现简单性与兼容性**：将盐与密文一起存储（例如 `salt|iv|ciphertext`）是最简单、最可靠的方式。它避免了单独管理盐的秘密通道，简化了系统设计，并确保解密时能准确获取所需的盐值。
4.  **不影响密钥强度**：盐值本身并不包含密钥信息。最终的加密强度仍由用户密码的熵值、密钥派生函数的强度以及加密算法本身决定。盐只是确保这些要素在一个独特的环境中发挥作用。

**总结来说：** 动态盐是加密系统的“扰动因子”，它通过引入强制的、公开的随机性，将每个用户的加密过程变成独立的安全堡垒。即使盐值公开，它也迫使攻击者从高效的“批量流水线作业”模式，退回到低效的“逐个手工攻坚”模式，极大地提升了系统的整体安全性。盐的公开性非但不是弱点，反而是其安全机制透明化和可验证性的体现。


查看DNS服务的IP地址
--------------------

在Window平台执行如下指令查看DNS服务的IP地址

```ps
Get-DnsClientServerAddress -AddressFamily IPv4 | Format-Table -AutoSize
```

例如

```
InterfaceAlias              InterfaceIndex AddressFamily ServerAddresses
--------------              -------------- ------------- ---------------
vEthernet (以太网 2)                    33 IPv4          {}
vEthernet (Default Switch)              38 IPv4          {}
以太网 2                                11 IPv4          {192.168.1.1}
蓝牙网络连接                            13 IPv4          {}
Loopback Pseudo-Interface 1              1 IPv4          {}
```


编译器如何帮助CPU更好的实现分支预测
---------------------------------


总所周知, 分支预测的准确性对于CPU的执行性能有很大的影响, 而GCC提供了 `likely(x)` 和 `unlikely(x)` 宏来实现分支预测的提示. 那么GCC是怎么做到的呢?

GCC 的分支提示 (likely/unlikely) ​​不直接​​向硬件预测器发送命令或设置其内部状态。它无法控制预测器在运行时如何做决策。但通过改变代码布局，GCC 使得

- 对于标记为 likely 的条件，其最可能路径（then）正好是硬件预测器​​默认倾向预测​​的路径（fall-through）。
- 对于标记为 unlikely 的条件，其最可能路径（else）也正好是硬件预测器​​默认倾向预测​​的路径（fall-through）。

这样，硬件预测器的​​静态预测策略​​（通常是预测 fall-through 或向后跳转为 Taken，向前跳转为 Not-Taken）就能在第一次或模式不明确时，更大概率地猜中实际的分支走向。预测器会​​持续学习​​分支的历史行为（动态预测），但一个好的初始布局（由编译器根据提示生成）可以减少预测器学习过程中的错误预测次数。


- [CPU是如何猜对if分支的？](https://www.bilibili.com/video/BV1hBhezVErM/)
- [CPU架构全览：CPU微架构又是啥？](https://www.bilibili.com/video/BV1844y1z7Dx/)


Protobuf相关知识
================


protobuf是一种将结构化数据序列化的机制, 可用于内部设备通信或存储. 与JSON格式相比, 基于protobuf协议的二进制文件体积更小, 解析速度更快.




protobuf简介
----------------

### 类型

| 类型                                 | 解释                               |
| ------------------------------------ | ---------------------------------- |
| float, double                        | 浮点数                             |
| int32, int64, uint32, uint64         | 整数，但不适合编码较大的数字和负数 |
| sint32, sint64                       | 针对负数进行优化的整数类型         |
| fixed32, fixed64, sfixed32, sfixed64 | 更适合大数字的有符号数或无符号数   |
| bool                                 | 布尔值                             |
| string                               | 任意的UTF-8字符串                  |
| byte                                 | 任意的字节                         |

protobuf对数字存储进行了优化，一个数字越小则存储长度越短。由于计算机使用补码表示负数，因此通常情况下负数将使用多个字节表示。为了优化这种情况，sint类型使用交叉的方式表示，绝对值较小的负数依然可以获得较短的存储长度。

- [官方文档](https://developers.google.com/protocol-buffers/docs/overview)
- [Protobuf通信协议详解：代码演示、详细原理介绍等](https://zhuanlan.zhihu.com/p/141415216)
- [proto2格式说明](https://developers.google.com/protocol-buffers/docs/proto)
- [proto3格式说明](https://developers.google.com/protocol-buffers/docs/proto3)



protobuf命名冲突解决方案
------------------------

对于PB的namespace, 规范要求每个PB都是全局唯一的. 如果设计不合理就会导致PB名称冲突, 对于高版本的依赖库, Go语言在启动时会直接painc, 导致系统无法启动. 

对于上述问题, 可以通过降级依赖版本临时解决:

```go
replace (
	github.com/golang/protobuf => github.com/golang/protobuf v1.4.3
	google.golang.org/protobuf => google.golang.org/protobuf v1.25.0
)
```


Protocol Buffers (PB) 的设计哲学与反序列化安全
--------------------

PB 通过其“契约优先、编译时绑定、数据纯填充”的设计理念，天然地规避了 Java 原生序列化及某些 JSON 库中常见的反序列化漏洞，为现代分布式系统提供了安全、高效的数据交换基石。

一、 漏洞根源：超越“数据填充”的复杂重建

Java 原生序列化漏洞（如 Common-Collections 利用链）的根源在于其设计目标：完美重建任意复杂的对象图。为实现此目标，它必须：
1.  动态加载类： 根据流中嵌入的类名，通过 ClassLoader 动态加载未知的 .class 文件。
2.  执行回调方法： 在反序列化过程中，自动调用特定方法（如 readObject、readResolve），以恢复对象状态。
3.  处理复杂关系： 自动管理循环引用、继承关系等。

这种复杂性创造了攻击面。攻击者可以精心构造一条 “利用链 (Gadget Chain)”：从一个可序列化类的 readObject 方法开始，通过一系列库中的类的方法调用，最终触发危险操作（如 Runtime.exec()）。其本质是数据流中包含的“指令”被反序列化过程“执行”了。

二、 PB 的设计反击：坚守“数据编码器”的本分

PB 的设计哲学截然不同。它放弃了“完美对象图重建”的宏大目标，将自身严格限定为一个高效的“结构化数据编码器”。其核心理念体现在：

1.  契约优先 (Schema First)： 所有数据结构必须预先在 .proto 文件中明确定义。该文件是独立于语言的、不变的契约。
2.  编译时类型绑定： 通过 protoc 编译器，将 .proto 契约编译成各语言的强类型代码（如 Java 的 User 类）。类型信息在编译时即被硬编码至生成的代码中。
3.  无动态行为： PB 的序列化 (toByteArray) 和反序列化 (parseFrom) API 仅操作生成的、具体的数据容器类。过程如下：
    *   序列化： 将已知类型的对象数据按契约编码为二进制流。
    *   反序列化： 根据调用方指定的目标类型（如 User.parseFrom），严格按照契约将二进制流解码并填充至该类型的对象中。
4.  无回调机制： 整个过程仅是数据拷贝，绝不会调用任何用户定义的构造函数、初始化方法或类似 readObject 的回调。

三、 关键差异与安全优势

特性 Java 原生序列化 / 危险JSON特性 Protocol Buffers 安全优势

类型信息 动态，来自数据流 (className, @type) 静态，来自契约和编译生成 杜绝动态类加载，攻击者无法指定任意类。

反序列化过程 复杂对象图重建，可能执行回调 纯数据填充 无代码执行，无法触发利用链。

多态处理 危险：依赖数据流指定具体类 安全：显式字段标识 + oneof 或 Any + 白名单 接收方主动选择处理已知类型，而非被动加载。

数据流内容 类名、字段名、对象引用句柄等元数据 仅字段编号 (Tag) 和值 (Value) 流中无指令，仅为数据，无法操控解析逻辑。

四、 总结：安全源于克制与显式

PB 的安全优势并非偶然，而是其克制、显式、契约驱动的设计哲学的必然结果。

*   克制 (Restraint)： 它主动放弃了“智能”地重建行为与复杂类型的功能，选择了功能上的“简单”，换取了安全性和性能上的“强大”。
*   显式 (Explicitness)： 所有类型都在编译时确定，所有操作都通过生成的强类型 API 进行。没有隐藏的魔法行为，一切皆可预测。
*   契约驱动 (Contract-Driven)： 通信双方严格依赖共享的 .proto 契约，而非嵌入在数据流中的隐含信息。这确保了数据解析的一致性和安全性。

因此，在技术选型中，PB 因其内在的安全属性，成为微服务通信、数据持久化等场景下的稳妥首选。它提醒我们，在软件设计中，通过限定边界、简化模型、显式约定，往往能从根本上规避一整类的复杂问题，反序列化漏洞正是其中之一。与之相比，在 JSON 中使用 @type 等功能，是一种为了便利性而牺牲安全性的危险妥协，应极力避免。


---

FastJSON（特别是其 `autoType` 特性）的设计理念与 Protocol Buffers 的“契约优先、编译时绑定”原则形成鲜明对比，这种差异直接导致了其高频发的安全漏洞。FastJSON允许 JSON 数据通过 **`@type` 字段动态指定任意类名**（如 `"@type": "com.attacker.Exploit"`）。将**类型解释权交给不可信的数据流**，而非预先定义的契约。攻击者可注入恶意类名，触发类加载。即使开启 `autoType` 白名单，攻击者仍可利用未覆盖的 JDK 或第三方库危险类（如 `BasicDataSource`）。或者利用未覆盖的 JDK 或第三方库危险类（如 `BasicDataSource`）。



有趣的项目推荐
================

- [基于命令行的浏览器](https://fathy.fr/carbonyl#drawing)


Github使用
================


免费开发环境
------------------

每月可免费使用120核心小时的服务器资源.  停止运行后, 不计算核心小时资源, 仅计算存储资源. 
 
默认启用2核心服务器, 可使用60小时, 平均每天可使用2小时. 30min无操作自动关闭, 几乎等于无限制使用.
 
 
- [配额说明](https://docs.github.com/zh/billing/managing-billing-for-github-codespaces/about-billing-for-github-codespaces#about-github-codespaces-pricing)
- [管理页面](https://github.com/codespaces)


Calibre优化
=================


书籍样式修改
---------------

对于EPUB格式的数据, 实际上就是压缩格式的HTML代码, 因此可以使用HTML的技术进行修改, 例如调整文字行间距, 可使用属性

```html
<p style="line-height:1.5;">
```

将行间距调整为1.5倍



机器学习
===============


大模型提示词
---------------

- 赛博人格分裂，(启动人格分裂讨论模式+问题)
- 阴阳怪气模式，(问题+笑死)毒舌属性
- 触发预判模式，假设性问题(如果，，，会不会，，，)
- 预言家模式，预判未来(如果，，，会发生什么)
- 灵魂拷问模式，(①启动杠精模式②先写方案，再模拟杠精从*个角度狂喷，最后给出V2版方案)，
- 玄学编程(，，，带点蝉意)
- 驯服转业话痨，(说人话！)
- 人设粘贴术，
- 启动老板思维(如果你是，，，你会怎么骂这个方案)
- 过滤废话，(问题，+删掉所有正确的废话，只留能落地的建议)



高性能服务设计原则
====================

无状态, 轻重分离, 消息队列, 缓存.

无锁化: 串行无锁 结构无锁
零拷贝: 内存映射 零拷贝
序列化: 性能 选型
池子化: 内存池 线程池 连接池 对象池
并发化: 请求并发 请求冗余
异步化: 调用异步化 流程异步化
缓存: 使用场景 回收策略 清理与修复
分片: 分片策略 二级索引 路由策略 动态平衡 分库分表 任务分片
存储: 读写分离 动静分离 冷热分离 重写轻读 数据异构
队列: 异步处理 流量削峰 系统解耦 数据同步 柔性事务
监控: 指标监测 指标告警
限流: 限流熔断 负载均衡