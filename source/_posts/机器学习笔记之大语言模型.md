---
title: 机器学习笔记之大语言模型
date: 2025-03-22 22:09:06
categories: 机器学习
tags:
    - 机器学习
cover_picture: images/ml.jpg
math: true
---



BBPE算法
-------------

Byte-level Byte-Pair Encoding（BBPE）是BPE（Byte-Pair Encoding）算法的改进版本，核心思想是将文本处理粒度从字符级别扩展到**字节级别**，通过UTF-8编码支持多语言文本的分词。以下是其关键点：

### 1. **基本原理**
BBPE基于BPE框架，但初始词表由**256个字节**（0-255）构成，而非字符。文本通过UTF-8编码转换为字节序列后，算法统计相邻字节对的频率，逐步合并高频对以构建子词词表。例如：中文“你好”的UTF-8字节表示为`\xe4\xbd\xa0\xe5\xa5\xbd`，BBPE会统计这些字节对的频率并合并高频组合（如`\xe4\xbd`和`\xa0`）。

### 2. **实现步骤**
1. **初始化词表**：包含所有256个可能的字节。
2. **统计频率**：统计训练语料中相邻字节对的出现频率。
3. **合并高频对**：选择频率最高的字节对合并为新子词，更新词表。
4. **迭代合并**：重复上述步骤，直到达到预设词表大小或无法继续合并。

### 3. **与BPE的区别**
| 对比项          | BPE                          | BBPE                          |
|-----------------|------------------------------|-------------------------------|
| **初始词表**    | 字符级别（如字母、汉字）      | 字节级别（256个UTF-8字节）     |
| **处理粒度**    | 字符（如“a”、“汉”）           | 字节（如`\xe4`、`\xbd`）       |
| **多语言支持**  | 需为不同语言单独训练词表      | 通用，支持任意语言混合文本     |
| **OOV处理**     | 可能无法处理罕见字符          | 无OOV（所有字符可分解为字节）  |

传统的BPE存在分析统一性问题，不同语言的字符集差异大（如中文汉字 vs 英文字母），需为每种语言单独训练词表，导致多语言模型词表臃肿且难以共享子词。对低频字符（如罕见汉字、特殊符号）容易触发OOV。

### 4. **优缺点**
- **优点**：
  - **多语言通用性**：通过字节处理，无需为不同语言设计单独词表。
  - **无OOV问题**：任何字符均可通过UTF-8编码为字节序列。避免模型在遇到**未在训练词表中出现过的词汇**时，无法正确表示或处理这些词汇的现象。
- **缺点**：
  - **计算复杂度高**：初始词表较大（256字节相较于26个字母），合并次数多。
  - **语义信息弱**：字节级合并可能生成无明确语义的子词。

### 5. **应用场景**
BBPE广泛应用于多语言模型（如GPT系列、Qwen系列），因其能统一处理混合语言文本，例如：
- 英文单词“chat”和中文“聊天”分别编码为字节序列后，BBPE可生成共享子词（如`\x68\x61`对应“ha”）。

总结来看，BBPE通过字节级处理实现了更强的通用性，是当前多语言模型分词的主流方法之一。



针在干草堆中测试
-------------------------

#### **1. 定义与目的**
**“针在干草堆中”测试**是一种用于评估机器学习模型（尤其是大语言模型）在**长文本中定位关键信息**能力的基准测试。其核心思想是模拟从海量无关信息（“干草堆”）中精准提取特定目标信息（“针”）的场景，检验模型的**长上下文理解**、**信息检索**和**抗噪声干扰**能力。

#### **2. 典型应用场景**
- **长文本问答**：测试模型能否从数万字的文档中回答依赖特定细节的问题。  
  *示例*：在一篇100页的研究报告中，要求模型找到“实验组样本量”的具体数值。
- **噪声鲁棒性**：评估模型在冗余或干扰信息中保持准确性的能力。  
  *示例*：在包含大量无关对话的文本中，定位关键事件的时间点。
- **多语言/跨模态处理**：测试模型对混合语言、代码或结构化数据的敏感度。  
  *示例*：从混杂中英文的会议纪要中提取中文提到的项目预算。

---

#### **3. 测试设计方法**
1. **构造“干草堆”**：  
   - 生成或选取长文本（通常数万至数十万token），内容包含冗余、重复或无关信息。
   - 可插入多种干扰类型：随机段落、无关对话、多语言混合、代码片段等。

2. **插入“针”**：  
   - 在文本的随机位置插入目标信息（“针”），如特定事实、数值、日期或短句。
   - 可能设计多根“针”以测试多目标检索能力。

3. **设计问题**：  
   - 提问需直接关联“针”的内容，但避免使用与“针”完全相同的表述。  
   *示例*：  
   - 插入内容：“项目最终成本为\$2.14亿”（针）  
   - 提问：“本次项目的总支出是多少？”

4. **评估指标**：  
   - **准确率**：模型能否返回“针”中的正确答案。  
   - **响应速度**：模型处理长文本的效率（如token/秒）。  
   - **抗干扰性**：插入“针”的位置（开头/中间/结尾）对结果的影响。

---

#### **4. 技术挑战与模型表现**
- **上下文窗口限制**：  
  多数模型对长文本的注意力权重会随距离衰减，导致远距离“针”的定位失败。  
  *实验数据*：GPT-4在10万token文本中，若“针”位于末尾，准确率可能下降15-20%。
- **语义干扰**：  
  当“干草堆”中存在语义相似的干扰项时，模型易产生混淆。  
  *示例*：插入多个相近日期（如“2023-05-01”和“2023-05-10”），要求提取特定日期。
- **多模态混合**：  
  若“干草堆”包含表格、代码或图片OCR文本，模型需跨模态对齐信息。

---

#### **5. 与其他测试的对比**
| 测试类型          | 关注点                  | 典型任务                | NIAH的独特性               |
|-------------------|-------------------------|-------------------------|---------------------------|
| **MMLU**          | 多学科知识掌握          | 选择题形式的专业知识问答 | 强调长文本细粒度检索       |
| **DROP**          | 数值推理与定位          | 从段落中提取数字/日期    | 增加噪声和长度复杂度       |
| **TriviaQA**      | 事实性知识召回          | 开放领域问答             | 强制模型处理无关上下文     |

---

#### **6. 实际应用案例**
- **法律文档分析**：  
  从数百页的合同中找到特定条款（如“违约赔偿金额”），测试模型在法律领域的实用性。
- **医疗记录检索**：  
  在患者长达10年的病历中定位关键化验结果（如“2022年血糖峰值”），评估医疗AI的可靠性。
- **代码库维护**：  
  在开源项目的历史提交记录中查找特定API的变更说明，验证模型对技术文档的处理能力。

---

#### **7. 当前模型的局限性**
- **位置偏差**：  
  多数模型对文本开头/结尾的信息更敏感，中间部分“针”的丢失率较高。  
  *数据*：在20万token文本中，中间1/3区域的“针”召回率比首尾低30-40%。
- **过度泛化**：  
  当“针”的信息与“干草堆”中的常见模式冲突时，模型可能错误“纠正”答案。  
  *示例*：若“干草堆”多次提到“成本\$1.8亿”，但“针”为“成本\$2.14亿”，模型可能返回错误高频率值。
- **计算成本**：  
  处理超长文本需要消耗大量显存，限制实时应用（如128k token的推理需16GB+显存）。

---

### **总结**
NIAH测试通过极端场景（高噪声+长上下文）暴露模型的检索弱点，推动以下技术改进：
1. **更高效的注意力机制**（如滑动窗口、稀疏注意力）。
2. **检索增强生成（RAG）**：结合外部数据库辅助定位。
3. **长文本微调策略**：专门训练模型对远距离依赖的捕捉能力。

该测试已成为评估GPT-4、Claude-3等长上下文模型的核心基准之一。



模型蒸馏
-----------

模型蒸馏是将大型AI模型（教师模型）的知识蒸馏（Distillation）到小型模型（学生模型）的过程，旨在通过迁移知识使小模型在保持较低计算资源需求的同时，尽可能接近大模型的性能。

首先训练一个高性能的大模型（如BERT、GPT等），作为知识提供者。此训练过程是标准的模型训练过程（监督学习）。然后设计一个参数更少、结构更简单的小模型（如TinyBERT、DistilBERT等）。学生模型结构需与教师模型兼容（例如，层数减少但维度对齐）。通过简化架构（减少层数、注意力头数）、量化或剪枝降低计算成本。

---

蒸馏的关键是让学生模型模仿教师模型的输出，通常通过以下两种损失函数结合实现：

**（1）软目标损失（Soft Target Loss）**: 教师模型通过提高“温度”参数 \( T \)（\( T > 1 \)）软化输出概率分布，使不同类别的概率差异更平滑（例如，将原始logits除以 \( T \) 后再做Softmax）。学生模型在相同温度下输出概率，并与教师模型的软化概率计算损失（如KL散度）。

$$
\mathcal{L}_{\text{soft}} = \text{KL}\left( \sigma\left(\frac{\mathbf{z}_{\text{teacher}}}{T}\right) \parallel \sigma\left(\frac{\mathbf{z}_{\text{student}}}{T}\right) \right)
$$

其中 \( \sigma \) 是Softmax函数，\( \mathbf{z} \) 为模型输出的logits。

> 如何理解温度的作用? 实际上就是把每个神经元输出同时缩小相同的倍数, 那么经过softmax处理后相对的差距就会缩小. 例如可以考虑T为无穷大时, 最终输出将会是一个均匀分布. 因此温度操作通常可视为对输出进行"平滑"或者"软化"

**（2）硬目标损失（Hard Target Loss）**: 学生模型还需直接学习真实标签（Ground Truth），通常用交叉熵损失：

$$
\mathcal{L}_{\text{hard}} = \text{CrossEntropy}(y_{\text{true}}, \mathbf{z}_{\text{student}})
$$


**总损失函数**: 综合两者，通过权重系数 \( \lambda \) 平衡：

$$
\mathcal{L}_{\text{total}} = \lambda \cdot \mathcal{L}_{\text{soft}} + (1 - \lambda) \cdot \mathcal{L}_{\text{hard}}
$$

> 这个$\lambda$可以说是机器学习味道最浓郁的部分


---


### 为什么知识蒸馏是有效的

1. 信息熵视角: 高温软化后的分布具有更高的熵（不确定性），传递了更多信息，而低熵分布（如硬标签）信息量较少。知识蒸馏的本质是通过最大化教师模型输出的熵来传递更多知识。
2. 梯度匹配理论: 学生模型通过匹配教师模型的梯度方向（而非仅输出值）来学习，高温软化后的分布能提供更稳定的梯度信号，避免陷入局部最优。

> 用信息熵来解释, 确实是有点数学理论.

学生模型通过拟合高温软化后的分布，不仅能学到“猫”是正确类别，还能理解“豹”比“卡车”更接近正确答案。这种隐含的类别相似性知识，显著提升了小模型的泛化能力。蒸馏后的小模型不仅能“知其然”（预测结果），还能“知其所以然”（类别间的推理逻辑），最终在轻量化的同时保持高性能。

---------

此外, 除了在最初输出层对齐结果外, 还可以在中间层对齐, 例如强迫学生模型的中间层特征（如注意力矩阵、隐藏状态）与教师模型对齐（如FitNets、TinyBERT）。这些中间层包含了许多隐含的知识, 而采取一般的训练方法很难是学生模型获取到这类知识.


